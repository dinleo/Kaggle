{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc84ed0",
   "metadata": {
    "papermill": {
     "duration": 0.009968,
     "end_time": "2023-11-03T11:07:50.362283",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.352315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM - Detect AI Generated Text\n",
    "> Identify which essay was written by a large language model\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/36858976/279902422-b365f6ef-ef01-49ac-af7f-0bc2ca3ba835.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747d2c5",
   "metadata": {
    "papermill": {
     "duration": 0.009061,
     "end_time": "2023-11-03T11:07:50.381082",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.372021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üéØ | Motivation\n",
    "\n",
    "* In this notebook, we will demonstrate the usage of the multi-backend capabilities of `KerasCore` and `KerasNLP` for the **Detect Fake Text** infernece."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cffedf",
   "metadata": {
    "papermill": {
     "duration": 0.008952,
     "end_time": "2023-11-03T11:07:50.399317",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.390365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìì | Notebooks\n",
    "\n",
    "* Train: [Detect Fake Text: KerasNLP [TF/Torch/JAX][Train]](https://www.kaggle.com/code/awsaf49/detect-fake-text-kerasnlp-tf-torch-jax-train)\n",
    "* Infer: [Detect Fake Text: KerasNLP [TF/Torch/JAX][Infer]](https://www.kaggle.com/code/awsaf49/detect-fake-text-kerasnlp-tf-torch-jax-infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5c601",
   "metadata": {
    "papermill": {
     "duration": 0.008928,
     "end_time": "2023-11-03T11:07:50.417435",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.408507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üõ† | Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdad111e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-03T11:07:50.438042Z",
     "iopub.status.busy": "2023-11-03T11:07:50.437124Z",
     "iopub.status.idle": "2023-11-03T11:08:37.468269Z",
     "shell.execute_reply": "2023-11-03T11:08:37.467172Z"
    },
    "papermill": {
     "duration": 47.043954,
     "end_time": "2023-11-03T11:08:37.470635",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.426681",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:27:50.413384700Z",
     "start_time": "2023-12-07T07:27:50.060298400Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install /kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.7-py3-none-any.whl --no-deps\n",
    "# !pip install /kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.2-py3-none-any.whl --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a5988",
   "metadata": {
    "papermill": {
     "duration": 0.010165,
     "end_time": "2023-11-03T11:08:37.491304",
     "exception": false,
     "start_time": "2023-11-03T11:08:37.481139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6edb7c8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:37.512852Z",
     "iopub.status.busy": "2023-11-03T11:08:37.512540Z",
     "iopub.status.idle": "2023-11-03T11:08:49.609104Z",
     "shell.execute_reply": "2023-11-03T11:08:49.608286Z"
    },
    "papermill": {
     "duration": 12.110162,
     "end_time": "2023-11-03T11:08:49.611447",
     "exception": false,
     "start_time": "2023-11-03T11:08:37.501285",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:04.347319500Z",
     "start_time": "2023-12-07T07:27:50.081308600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras_core as keras \n",
    "import keras_core.backend as K\n",
    "\n",
    "\n",
    "# import jax\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4785be",
   "metadata": {
    "papermill": {
     "duration": 0.010039,
     "end_time": "2023-11-03T11:08:49.632281",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.622242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378f19b9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.654342Z",
     "iopub.status.busy": "2023-11-03T11:08:49.653755Z",
     "iopub.status.idle": "2023-11-03T11:08:49.659557Z",
     "shell.execute_reply": "2023-11-03T11:08:49.658653Z"
    },
    "papermill": {
     "duration": 0.019033,
     "end_time": "2023-11-03T11:08:49.661570",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.642537",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:04.366324900Z",
     "start_time": "2023-12-07T07:28:04.350319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.1\n",
      "Keras: 0.1.7\n",
      "KerasNLP: 0.6.3\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"JAX:\", jax.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ed4eb",
   "metadata": {
    "papermill": {
     "duration": 0.010081,
     "end_time": "2023-11-03T11:08:49.682148",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.672067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚öôÔ∏è | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cfdaf7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.704337Z",
     "iopub.status.busy": "2023-11-03T11:08:49.703669Z",
     "iopub.status.idle": "2023-11-03T11:08:49.709506Z",
     "shell.execute_reply": "2023-11-03T11:08:49.708674Z"
    },
    "papermill": {
     "duration": 0.018903,
     "end_time": "2023-11-03T11:08:49.711315",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.692412",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:04.436330900Z",
     "start_time": "2023-12-07T07:28:04.366324900Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TEST_PATH = './kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv'\n",
    "    VACAB_PATH = './kaggle/Model/keras-nlp-deberta-v3-base-en-vocab-ds/vocab.spm'\n",
    "    CKPT_PATH = \"./kaggle/working/\"  # Name of pretrained models\n",
    "    preset = \"deberta_v3_small_en\"  # Name of pretrained models\n",
    "    num_of_dataset = 1000 # Num of test dataset\n",
    "    verbose = 0  # Verbosity\n",
    "    device = 'GPU'  # Device\n",
    "    seed = 42  # Random seed\n",
    "    batch_size = 10  # Batch size\n",
    "    drop_remainder = True  # Drop incomplete batches\n",
    "    sequence_length = 200  # Input sequence length\n",
    "    class_names = ['real','fake']  # Class names [A, B, C, D, E]\n",
    "    num_classes = len(class_names)  # Number of classes\n",
    "    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n",
    "    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n",
    "    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613197e",
   "metadata": {
    "papermill": {
     "duration": 0.009903,
     "end_time": "2023-11-03T11:08:49.731571",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.721668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚ôªÔ∏è | Reproducibility \n",
    "Sets value for random seed to produce similar result in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0bae00",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.753146Z",
     "iopub.status.busy": "2023-11-03T11:08:49.752841Z",
     "iopub.status.idle": "2023-11-03T11:08:49.760601Z",
     "shell.execute_reply": "2023-11-03T11:08:49.759893Z"
    },
    "papermill": {
     "duration": 0.020701,
     "end_time": "2023-11-03T11:08:49.762469",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.741768",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:04.448330Z",
     "start_time": "2023-12-07T07:28:04.380324500Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49606d31",
   "metadata": {
    "papermill": {
     "duration": 0.009993,
     "end_time": "2023-11-03T11:08:49.782764",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.772771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üíæ | Hardware\n",
    "Following codes automatically detects hardware (TPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16e7d57",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.804918Z",
     "iopub.status.busy": "2023-11-03T11:08:49.804604Z",
     "iopub.status.idle": "2023-11-03T11:08:49.811913Z",
     "shell.execute_reply": "2023-11-03T11:08:49.811096Z"
    },
    "papermill": {
     "duration": 0.020656,
     "end_time": "2023-11-03T11:08:49.813818",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.793162",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:04.449334100Z",
     "start_time": "2023-12-07T07:28:04.396847200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"Detect and intializes GPU/TPU automatically\"\n",
    "    try:\n",
    "        # Connect to TPU\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n",
    "        # Set TPU strategy\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
    "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
    "        device=CFG.device\n",
    "    except:\n",
    "        # If TPU is not available, detect GPUs\n",
    "        gpus = tf.config.list_logical_devices('GPU')\n",
    "        ngpu = len(gpus)\n",
    "         # Check number of GPUs\n",
    "        if ngpu:\n",
    "            # Set GPU strategy\n",
    "            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
    "            # Print GPU details\n",
    "            print(\"> Running on GPU\", end=' | ')\n",
    "            print(\"Num of GPUs: \", ngpu)\n",
    "            device='GPU'\n",
    "        else:\n",
    "            # If no GPUs are available, use CPU\n",
    "            print(\"> Running on CPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            device='CPU'\n",
    "    return strategy, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e0f73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.836104Z",
     "iopub.status.busy": "2023-11-03T11:08:49.835219Z",
     "iopub.status.idle": "2023-11-03T11:08:54.677299Z",
     "shell.execute_reply": "2023-11-03T11:08:54.676216Z"
    },
    "papermill": {
     "duration": 4.855228,
     "end_time": "2023-11-03T11:08:54.679293",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.824065",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:05.981772300Z",
     "start_time": "2023-12-07T07:28:04.409849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPU/TPU/TPU-VM\n",
    "strategy, CFG.device = get_device()\n",
    "CFG.replicas = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090d5db",
   "metadata": {
    "papermill": {
     "duration": 0.010473,
     "end_time": "2023-11-03T11:08:54.700467",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.689994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÅ | Dataset Path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba01642",
   "metadata": {
    "papermill": {
     "duration": 0.00999,
     "end_time": "2023-11-03T11:08:54.748096",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.738106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìñ | Meta Data \n",
    "* `{test|train}_essays.csv`\n",
    "    * `id` - A unique identifier for each essay.\n",
    "    * `prompt_id` - Identifies the prompt the essay was written in response to.\n",
    "    * `text` - The essay text itself.\n",
    "    * `generated` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv.\n",
    "* **sample_submission.csv** - is the valid sample submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb67d6",
   "metadata": {
    "papermill": {
     "duration": 0.009916,
     "end_time": "2023-11-03T11:08:54.768279",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.758363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69dd6aa",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:54.790159Z",
     "iopub.status.busy": "2023-11-03T11:08:54.789627Z",
     "iopub.status.idle": "2023-11-03T11:08:54.816082Z",
     "shell.execute_reply": "2023-11-03T11:08:54.815167Z"
    },
    "papermill": {
     "duration": 0.039582,
     "end_time": "2023-11-03T11:08:54.818058",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.778476",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:07.200556Z",
     "start_time": "2023-12-07T07:28:05.977766100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Data: 1,000\n",
      "# Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": "           essay_id                                               text  label  \\\n2049   570D3C7684D2  Dear principal,\\n\\nPolicy 1 is better because ...      0   \n13505  A9FEE9B7208B  What happen on Mars. In May 24, 2001. One of o...      0   \n\n                source prompt  fold  \n2049   persuade_corpus    NaN     6  \n13505  persuade_corpus    NaN     2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>source</th>\n      <th>prompt</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2049</th>\n      <td>570D3C7684D2</td>\n      <td>Dear principal,\\n\\nPolicy 1 is better because ...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13505</th>\n      <td>A9FEE9B7208B</td>\n      <td>What happen on Mars. In May 24, 2001. One of o...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ext_df1 = pd.read_csv(CFG.TEST_PATH)  # Read CSV file into a DataFrame\n",
    "test_df = pd.concat([\n",
    "    ext_df1[ext_df1.label==0].sample(CFG.num_of_dataset//2),\n",
    "    ext_df1[ext_df1.label==1].sample(CFG.num_of_dataset//2)\n",
    "])\n",
    "# Display information about the train data\n",
    "print(\"# Test Data: {:,}\".format(len(test_df)))\n",
    "print(\"# Sample:\")\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cddd0",
   "metadata": {
    "papermill": {
     "duration": 0.010564,
     "end_time": "2023-11-03T11:08:54.839359",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.828795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üçΩÔ∏è | Preprocessing\n",
    "\n",
    "**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n",
    "\n",
    "**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n",
    "\n",
    "Explore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n",
    "- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9cf143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:54.908622Z",
     "iopub.status.busy": "2023-11-03T11:08:54.908259Z",
     "iopub.status.idle": "2023-11-03T11:08:55.634837Z",
     "shell.execute_reply": "2023-11-03T11:08:55.633861Z"
    },
    "papermill": {
     "duration": 0.741063,
     "end_time": "2023-11-03T11:08:55.637326",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.896263",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:07.847448100Z",
     "start_time": "2023-12-07T07:28:07.194377600Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer= keras_nlp.models.DebertaV3Tokenizer(CFG.VACAB_PATH)\n",
    "preprocessor= keras_nlp.models.DebertaV3Preprocessor(tokenizer, sequence_length=CFG.sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4133aa",
   "metadata": {
    "papermill": {
     "duration": 0.01051,
     "end_time": "2023-11-03T11:08:55.658822",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.648312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601d1e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:55.681229Z",
     "iopub.status.busy": "2023-11-03T11:08:55.680879Z",
     "iopub.status.idle": "2023-11-03T11:08:55.967881Z",
     "shell.execute_reply": "2023-11-03T11:08:55.966667Z"
    },
    "papermill": {
     "duration": 0.300737,
     "end_time": "2023-11-03T11:08:55.970130",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.669393",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:14.627278400Z",
     "start_time": "2023-12-07T07:28:07.846446300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : torch.Size([200])\n",
      "padding_mask : torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "outs = preprocessor(test_df.text.iloc[0])  # Process options for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924c02d",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2023-11-03T11:08:55.992833",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.981216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52bf5fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.015458Z",
     "iopub.status.busy": "2023-11-03T11:08:56.015143Z",
     "iopub.status.idle": "2023-11-03T11:08:56.019857Z",
     "shell.execute_reply": "2023-11-03T11:08:56.019001Z"
    },
    "papermill": {
     "duration": 0.018277,
     "end_time": "2023-11-03T11:08:56.021784",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.003507",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:14.628278Z",
     "start_time": "2023-12-07T07:28:14.614276700Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebaaa0",
   "metadata": {
    "papermill": {
     "duration": 0.010385,
     "end_time": "2023-11-03T11:08:56.042774",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.032389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üçö | DataLoader\n",
    "\n",
    "The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n",
    "\n",
    "To learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f105f6fd",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.065193Z",
     "iopub.status.busy": "2023-11-03T11:08:56.064859Z",
     "iopub.status.idle": "2023-11-03T11:08:56.072439Z",
     "shell.execute_reply": "2023-11-03T11:08:56.071607Z"
    },
    "papermill": {
     "duration": 0.021202,
     "end_time": "2023-11-03T11:08:56.074442",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.053240",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:14.711310400Z",
     "start_time": "2023-12-07T07:28:14.634277600Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=False, drop_remainder=True,\n",
    "                  augment=False, repeat=False, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=5))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d96ee",
   "metadata": {
    "papermill": {
     "duration": 0.010464,
     "end_time": "2023-11-03T11:08:56.095644",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.085180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fetch Train/test Dataset\n",
    "\n",
    "The function below generates the training and testation datasets for a given fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c391e11a",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.118474Z",
     "iopub.status.busy": "2023-11-03T11:08:56.118153Z",
     "iopub.status.idle": "2023-11-03T11:08:56.123377Z",
     "shell.execute_reply": "2023-11-03T11:08:56.122518Z"
    },
    "papermill": {
     "duration": 0.018815,
     "end_time": "2023-11-03T11:08:56.125253",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.106438",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:14.738310300Z",
     "start_time": "2023-12-07T07:28:14.645278800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_dataset(test_df):\n",
    "    test_texts = test_df.text.tolist()  # Extract testation texts\n",
    "    \n",
    "    # Build testation dataset\n",
    "    test_ds = build_dataset(test_texts, labels=None,\n",
    "                             batch_size=min(CFG.batch_size*CFG.replicas, len(test_df)), cache=False,\n",
    "                             shuffle=False, drop_remainder=False, repeat=False)\n",
    "    \n",
    "    return test_ds  # Return datasets and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43b0d2",
   "metadata": {
    "papermill": {
     "duration": 0.010779,
     "end_time": "2023-11-03T11:08:56.146601",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.135822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ü§ñ | Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "146efed6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.169205Z",
     "iopub.status.busy": "2023-11-03T11:08:56.168866Z",
     "iopub.status.idle": "2023-11-03T11:08:56.174359Z",
     "shell.execute_reply": "2023-11-03T11:08:56.173500Z"
    },
    "papermill": {
     "duration": 0.018937,
     "end_time": "2023-11-03T11:08:56.176215",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.157278",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:14.742309700Z",
     "start_time": "2023-12-07T07:28:14.660276200Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Create a DebertaV3Classifier model\n",
    "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "        CFG.preset,\n",
    "        preprocessor=None,\n",
    "        num_classes=1 # one output per one option, for five options total 5 outputs\n",
    "    )\n",
    "    inputs = classifier.input\n",
    "    logits = classifier(inputs)\n",
    "        \n",
    "    # Compute final output\n",
    "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model with optimizer, loss, and metrics\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.AdamW(5e-6),\n",
    "        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.02),\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\"),\n",
    "        ],\n",
    "        jit_compile=True\n",
    "    )\n",
    "    model.distribute_strategy = strategy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949fa675",
   "metadata": {
    "papermill": {
     "duration": 0.010495,
     "end_time": "2023-11-03T11:08:56.197329",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.186834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ckpt processing\n",
    "For some reason, `keras.models.load_model` requires write access as `/kaggle/input` doesn't have that access it throws error. Workaround is to simply copy the `ckpts` to other directory then load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf4bec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.220194Z",
     "iopub.status.busy": "2023-11-03T11:08:56.219858Z",
     "iopub.status.idle": "2023-11-03T11:09:33.927801Z",
     "shell.execute_reply": "2023-11-03T11:09:33.926644Z"
    },
    "papermill": {
     "duration": 37.732553,
     "end_time": "2023-11-03T11:09:33.940839",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.208286",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:28:14.764311100Z",
     "start_time": "2023-12-07T07:28:14.690286100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CKPT: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the checkpoint directory and name\n",
    "CKPT_PATH = CFG.CKPT_PATH\n",
    "# ckpt_name = 'daigt-kerasnlp-ckpt'\n",
    "\n",
    "# Copy the checkpoints to a new directory in the /kaggle directory\n",
    "# !cp -r {CKPT_PATH} /kaggle/{ckpt_name}\n",
    "\n",
    "# List all the checkpoint paths in the new directory\n",
    "# new_ckpt_dir = f\"/kaggle/{ckpt_name}\"\n",
    "new_ckpt_dir = CKPT_PATH\n",
    "ckpt_paths = glob(os.path.join(new_ckpt_dir, '*.keras'))\n",
    "\n",
    "print(\"Total CKPT:\", len(ckpt_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bbff4",
   "metadata": {
    "papermill": {
     "duration": 0.011346,
     "end_time": "2023-11-03T11:09:33.963480",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.952134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß™ | Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47fce8c",
   "metadata": {
    "papermill": {
     "duration": 0.010664,
     "end_time": "2023-11-03T11:09:33.985041",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.974377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a6145f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:09:34.008721Z",
     "iopub.status.busy": "2023-11-03T11:09:34.008347Z",
     "iopub.status.idle": "2023-11-03T11:17:15.136923Z",
     "shell.execute_reply": "2023-11-03T11:17:15.136019Z"
    },
    "papermill": {
     "duration": 461.143679,
     "end_time": "2023-11-03T11:17:15.139776",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.996097",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:29:59.373362400Z",
     "start_time": "2023-12-07T07:28:14.706311700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8ae9be5e5174ff584d7dc12bbeff119"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kaggle/working\\fold1.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_core\\src\\trainers\\trainer.py:166: UserWarning: `jit_compile` is not yet enabled for the PyTorch backend. Proceeding with `jit_compile=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dinle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_core\\src\\saving\\serialization_lib.py:713: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m100/100\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 97ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize an array to store predictions for each fold\n",
    "fold_preds = np.zeros(shape=(len(test_df),), dtype='float32')\n",
    "\n",
    "# # Build model\n",
    "# model = build_model()\n",
    "\n",
    "# Iterate through each checkpoint path\n",
    "# for ckpt_path in tqdm(ckpt_paths):\n",
    "#     # Load the pre-trained model from the checkpoint\n",
    "#     print(ckpt_path)\n",
    "#     model = keras.models.load_model(\n",
    "#         ckpt_path,\n",
    "#         compile=False,\n",
    "#     )\n",
    "# #     model.load_weights(ckpt_path)\n",
    "#\n",
    "#     # Get the test dataset\n",
    "#     test_ds = get_test_dataset(test_df)\n",
    "#\n",
    "#     # Generate predictions using the model\n",
    "#     preds = model.predict(\n",
    "#         test_ds,\n",
    "#         batch_size=min(CFG.batch_size * CFG.replicas * 2, len(test_df)),  # Set batch size\n",
    "#         verbose=1\n",
    "#     )\n",
    "#\n",
    "#     # Add predictions to fold_preds and average over checkpoints\n",
    "#     fold_preds += preds.squeeze() / len(ckpt_paths)\n",
    "#\n",
    "#     # Clean up by deleting the model and collecting garbage\n",
    "#     del model\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = build_model()\n",
    "# Get the test dataset\n",
    "test_ds = get_test_dataset(test_df)\n",
    "\n",
    "# Generate predictions using the model\n",
    "preds = model.predict(\n",
    "    test_ds,\n",
    "    batch_size=min(CFG.batch_size * CFG.replicas * 2, len(test_df)),  # Set batch size\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Add predictions to fold_preds and average over checkpoints\n",
    "fold_preds += preds.squeeze()\n",
    "\n",
    "# Clean up by deleting the model and collecting garbage\n",
    "del model\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "11de9ef7",
   "metadata": {
    "papermill": {
     "duration": 0.011215,
     "end_time": "2023-11-03T11:17:15.162809",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.151594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7613b36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:17:15.187228Z",
     "iopub.status.busy": "2023-11-03T11:17:15.186591Z",
     "iopub.status.idle": "2023-11-03T11:17:15.193551Z",
     "shell.execute_reply": "2023-11-03T11:17:15.192694Z"
    },
    "papermill": {
     "duration": 0.021846,
     "end_time": "2023-11-03T11:17:15.195823",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.173977",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:29:59.394360100Z",
     "start_time": "2023-12-07T07:29:59.376360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Format predictions and true answers\n",
    "pred_answers = (fold_preds > 0.5).astype(int).squeeze()\n",
    "print(pred_answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions\n",
      "\n",
      "‚ùì Text 1:\n",
      "Dear principal,\n",
      "\n",
      "Policy 1 is better because that way students will be allowed to bring cell phones but will have to focus in class. Then they should be used in lunch breaks so they can take a break from class work. Also its best if they are allowed to bring to school because there can be emergencies and students can call home. Policy 1 is also better because during class time they can be learning and working but when its time for lunch they can use it that way it doesn't have to be only work. They can also have time to call home during break for something they need. Policy number one is also better because only during class it has to be off so they can focus on their work but later on when it is break they can choose to use it. The only time it can be off is during class but that's all, and when it is not class time their cell phones can be on and they will be able to use them without any problem because during class they will turn it off. So policy 1 is really best to use because during class they need to concentrate and do their best and for doing their work they get to use their cell phone after. Policy 2 is not better because students will bring their cell phones because they might need it to call their parents after school or something. So policy 1 is better and easier for students to follow. That way there wont be any problems on whether for students to bring their cell phones or not to school.\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 2:\n",
      "What happen on Mars. In May 24, 2001. One of our spacecraft took many photos of a human face that look like an Egyptian Pharaoh. People think that this is a symbol of life. What they dont know is that we have studied this symbol for a long time and there is no symbol of life on Mars.\n",
      "\n",
      "NASA sent one our space man Michael Malin to take some pictures with a better camera, revealing that their is no sign of alien life on Mars. \"But not everyone was not satified.\" In April, 1998 we sent another spacecaft to take pictures of Mars but it was to cloudy witch made it look like an alien markings.\n",
      "\n",
      "April 8, 2001 cloudless day, we sent another one of our viking spacecarft with a better camera so that we could see what we were really into. \"Malin team captured an extraordinary photo using maximum resolution.\"What the picture actually shows is the martian equivalent of a butte or mesa lanforms common around the American West.\"\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 3:\n",
      "In 1976, the Viking 1 set course to mars. When the Viking 1 was orbiting mars, the Mars Global Surveyor took a photo of a strange figure. It looked like a shadowy human face. The question everyone is asking is who are what made this? Was it aliens or is it just natural. If you ask me, this strange looking thing is just a natural landform.\n",
      "\n",
      "I think it is a landform for a couple of reasons. My first reason is that only a few of my friends from NASA believe that this strange landform was really made by aliens. I also think that this is just a landform because the photo that we took was not very clear and that could have made the landform look like a face.\n",
      "\n",
      "I also think that this is just a land form because the time of year that we took the one of the photos. When we took the photo in 1998, we took the photo during the winter on Mars and it made Mars sort of cloudy and the Mars Global Surveyer had to peer through the wispy clouds to see the strange landform. Some of my friends from NASA were saying that some of the so called \"alien markings\" were hidden too.\n",
      "\n",
      "My final reason for thinking that this is just a landform is that when we took the thre pictures and compared them, they all looked different from each other. The picture we took in 1976 looked like the face the most out of the three pictures. The picture we took in 1998 did not have the same details of the first picture and it did not look like a face. The picture we took in 2001 did not have the facial features of the first photo either. Therefore, I think this is just a landform\n",
      "\n",
      "In conclusion, I think this is just a landform because only a few of my friends believed that it was done by aliens, the photo we took in 1998 was different due to some of the factors of weather, and all three photos looked different from one another.      \n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 4:\n",
      "Dear Principal :\n",
      "\n",
      "I know you set high standards for us to achieve and you will get those soon, but in the mean time, I believe to participate in sports you should at least have above a D. Don't you Mrs. Principal?\n",
      "\n",
      "I believe we should support this because some students just cannot get things as fast as others and they just can't admit it, it is embarrassing and they will probably feel they don't have the knowledge and they will just get more depressed. Also they are trying their hardest.\n",
      "\n",
      "Also if you are so concerned you should just hold an adolescent-to-adolescent tutoring, you know peers teaching each other, because sometimes kids can just explain it in an easier and more comprehendible manner. This has been proven to work in other countries and also bring grades up 45%. I believe this have caught your major attention.\n",
      "\n",
      "Many kids are not able to participate in these sports because of the new 'school law' you just brought up. I have learned these kids do these sports to blow off steam and also just to not be ticked by anything tiny, like a fly set off their temper. Technically, you have just risen the bullying rate to 76.5%, yep, I just went there...\n",
      "\n",
      "You need to remove this \"law\" off this campus as fast as you can, ASAP! Change the law to: If you have a D- you will need to stay in after school teen-to-teen tutoring until 3:03.\n",
      "\n",
      "If you do this just would be doing this whole school a big favor in everyway.\n",
      "\n",
      "I would love to say thank you and hopefully we would do more friendly adult v. teen in the future.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "The Student Body\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 5:\n",
      "Dear Principal:\n",
      "\n",
      "I believe that cell phones cause problems when students are using them during class for texting, or going on the internet. However, they are very important for a student to have during the day. That is why I think Policy 1: Allow students to bring phones to school and use them during lunch periods and other free times, as long as the phones are turned off during class time, is the best policy.\n",
      "\n",
      "The main reason why I think that policy 1 is better is because the students may need their phone if they need some way to communicate with their parents before and after school. The students may need it if they find out their sport's practice is canceled, and they don't have a ride. They may also need to contact someone if there is some sort of emergency and they need help.\n",
      "\n",
      "However, students may also need their phones during the day as well. My older sister is a freshmen this year, but when she started at high school, she often times got lost so she would call her friends and ask them for help. Another important reason that students should be allowed to have their phones during the day is if they aren't feeling well and they need to come home for the rest of the day, they can call their parents or a friend to come pick them up.\n",
      "\n",
      "I believe that if a student is taking advantage of there privilege of even having a phone at school, and they are using it for social purposes, it should be taken away. But if a student does get caught, the teacher that confiscated it should return it to the owner after that class period. If a certain teacher is having problems with too many students having their phones out during class time, they should have every student place their phone at the far corner of their desk so the teacher can see everyone's phone and make sure no one is being distracted by them.\n",
      "\n",
      "If you use policy 2, I believe that students will feel like they have to sneak their phones into class, and that may cause a bigger problem. If students start taking in their phones secretly, more and more of them may get used to it and eventually start taking them out during class and you will end up in the same situation you are in right now. If you end up in this situation again, you will have to make more policies.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "STUDENT_NAME\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n"
     ]
    }
   ],
   "source": [
    "# Check 5 Predictions\n",
    "print(\"# Predictions\\n\")\n",
    "for i in range(5):\n",
    "    row = test_df.iloc[i]\n",
    "    text  = row.text\n",
    "    pred_answer = CFG.label2name[pred_answers[i]]\n",
    "    print(f\"‚ùì Text {i+1}:\\n{text}\\n\")\n",
    "    print(f\"ü§ñ Predicted: {pred_answer}\\n\")\n",
    "    print(\"-\"*90, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T07:29:59.461402100Z",
     "start_time": "2023-12-07T07:29:59.393365300Z"
    }
   },
   "id": "8abda16826ff3db6"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fold_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T07:29:59.478883900Z",
     "start_time": "2023-12-07T07:29:59.406363200Z"
    }
   },
   "id": "2a810999230dee0b"
  },
  {
   "cell_type": "markdown",
   "id": "243c4613",
   "metadata": {
    "papermill": {
     "duration": 0.011218,
     "end_time": "2023-11-03T11:17:15.218817",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.207599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÆ | Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1359dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:17:15.242714Z",
     "iopub.status.busy": "2023-11-03T11:17:15.242463Z",
     "iopub.status.idle": "2023-11-03T11:17:15.264108Z",
     "shell.execute_reply": "2023-11-03T11:17:15.263181Z"
    },
    "papermill": {
     "duration": 0.035702,
     "end_time": "2023-11-03T11:17:15.265937",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.230235",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-07T07:29:59.551879600Z",
     "start_time": "2023-12-07T07:29:59.426362800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct: 976 / 1000\n",
      "Acc: 97.60 %\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the submission\n",
    "sub_df = test_df.copy()\n",
    "\n",
    "# Add the formatted predictions to the submission DataFrame\n",
    "sub_df.drop(['source', 'prompt', 'fold'], axis=1, inplace=True)\n",
    "sub_df[\"pred_prob\"] = fold_preds.squeeze()\n",
    "sub_df[\"pred_label\"] = pred_answers\n",
    "sub_df[\"correct\"] = sub_df[\"pred_label\"] == sub_df[\"label\"]\n",
    "\n",
    "# Display the first 2 rows of the submission DataFrame\n",
    "sub_df.head(2)\n",
    "\n",
    "# Display Acc\n",
    "total_cor = sub_df[\"correct\"].sum()\n",
    "print(f'Total Correct: {total_cor} / {len(sub_df)}')\n",
    "print(f'Acc: {(total_cor * 100) / len(sub_df):.2f} %')\n",
    "\n",
    "# Save Submission\n",
    "sub_df.to_csv('./kaggle/working/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission_NoFine.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T07:30:59.125412100Z",
     "start_time": "2023-12-07T07:30:59.043943400Z"
    }
   },
   "id": "8857cd30ac69ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6ffd053fb2a38455"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 571.794825,
   "end_time": "2023-11-03T11:17:18.707885",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-03T11:07:46.913060",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16bae7a0a18f4c02b4c3da8e19f2245d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cffc34a76088491e9ce64b26c928f515",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_adb3d6ece1f247a0bc75f96cde5824fb",
       "value": 3.0
      }
     },
     "18d9748054464aa79345e251a618a993": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a40012713ee4900a539fd624a9f490a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4fef6e06395440228abc9c0ed870af81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_67a9a1a155544b058918db44bcf0ac2c",
        "IPY_MODEL_16bae7a0a18f4c02b4c3da8e19f2245d",
        "IPY_MODEL_8c55f9743fa745d0850cfb7a0caca1e5"
       ],
       "layout": "IPY_MODEL_d9f9892cfec647b1a6e667600470d307"
      }
     },
     "6317eb64a6d84c1385a2f74d0c58b9bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67a9a1a155544b058918db44bcf0ac2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d185c8d4593f4fb29d83ddd5147aa6c9",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_3a40012713ee4900a539fd624a9f490a",
       "value": "100%"
      }
     },
     "8c55f9743fa745d0850cfb7a0caca1e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6317eb64a6d84c1385a2f74d0c58b9bb",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_18d9748054464aa79345e251a618a993",
       "value": " 3/3 [07:41&lt;00:00, 152.83s/it]"
      }
     },
     "adb3d6ece1f247a0bc75f96cde5824fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cffc34a76088491e9ce64b26c928f515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d185c8d4593f4fb29d83ddd5147aa6c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9f9892cfec647b1a6e667600470d307": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
