{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc84ed0",
   "metadata": {
    "papermill": {
     "duration": 0.009968,
     "end_time": "2023-11-03T11:07:50.362283",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.352315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM - Detect AI Generated Text\n",
    "> Identify which essay was written by a large language model\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/36858976/279902422-b365f6ef-ef01-49ac-af7f-0bc2ca3ba835.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747d2c5",
   "metadata": {
    "papermill": {
     "duration": 0.009061,
     "end_time": "2023-11-03T11:07:50.381082",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.372021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🎯 | Motivation\n",
    "\n",
    "* In this notebook, we will demonstrate the usage of the multi-backend capabilities of `KerasCore` and `KerasNLP` for the **Detect Fake Text** infernece."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cffedf",
   "metadata": {
    "papermill": {
     "duration": 0.008952,
     "end_time": "2023-11-03T11:07:50.399317",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.390365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📓 | Notebooks\n",
    "\n",
    "* Train: [Detect Fake Text: KerasNLP [TF/Torch/JAX][Train]](https://www.kaggle.com/code/awsaf49/detect-fake-text-kerasnlp-tf-torch-jax-train)\n",
    "* Infer: [Detect Fake Text: KerasNLP [TF/Torch/JAX][Infer]](https://www.kaggle.com/code/awsaf49/detect-fake-text-kerasnlp-tf-torch-jax-infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5c601",
   "metadata": {
    "papermill": {
     "duration": 0.008928,
     "end_time": "2023-11-03T11:07:50.417435",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.408507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🛠 | Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdad111e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-03T11:07:50.438042Z",
     "iopub.status.busy": "2023-11-03T11:07:50.437124Z",
     "iopub.status.idle": "2023-11-03T11:08:37.468269Z",
     "shell.execute_reply": "2023-11-03T11:08:37.467172Z"
    },
    "papermill": {
     "duration": 47.043954,
     "end_time": "2023-11-03T11:08:37.470635",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.426681",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T06:19:28.499617600Z",
     "start_time": "2023-12-09T06:19:28.378068900Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install /kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.7-py3-none-any.whl --no-deps\n",
    "# !pip install /kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.2-py3-none-any.whl --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a5988",
   "metadata": {
    "papermill": {
     "duration": 0.010165,
     "end_time": "2023-11-03T11:08:37.491304",
     "exception": false,
     "start_time": "2023-11-03T11:08:37.481139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📚 | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6edb7c8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:37.512852Z",
     "iopub.status.busy": "2023-11-03T11:08:37.512540Z",
     "iopub.status.idle": "2023-11-03T11:08:49.609104Z",
     "shell.execute_reply": "2023-11-03T11:08:49.608286Z"
    },
    "papermill": {
     "duration": 12.110162,
     "end_time": "2023-11-03T11:08:49.611447",
     "exception": false,
     "start_time": "2023-11-03T11:08:37.501285",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T06:19:33.170367400Z",
     "start_time": "2023-12-09T06:19:28.388066800Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "When running Keras 2, the `KERAS_BACKEND` environment variable must either be unset or `'tensorflow'`. Received: `torch`. To set another backend, please install Keras 3. See https://github.com/keras-team/keras-nlp#installation",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      2\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKERAS_BACKEND\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# or \"tensorflow\" or \"torch\"\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras_core\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mK\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\__init__.py:8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m metrics\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\layers\\__init__.py:8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcached_multi_head_attention\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CachedMultiHeadAttention\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mf_net_encoder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FNetEncoder\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmasked_lm_head\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MaskedLMHead\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\src\\__init__.py:23\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m metrics\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\src\\layers\\__init__.py:15\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2023 The KerasNLP Authors\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcached_multi_head_attention\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     16\u001B[0m     CachedMultiHeadAttention,\n\u001B[0;32m     17\u001B[0m )\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mf_net_encoder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FNetEncoder\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmasked_lm_head\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MaskedLMHead\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\src\\layers\\modeling\\cached_multi_head_attention.py:15\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2023 The KerasNLP Authors\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_nlp_export\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\src\\api_export.py:17\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2023 The KerasNLP Authors\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnamex\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\src\\backend\\__init__.py:29\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2023 The KerasNLP Authors\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03mKeras backend module.\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;124;03m- `random`: `keras.random` for Keras 3 or `keras_core.ops` for Keras 2.\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras_nlp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_nlp\\src\\backend\\config.py:43\u001B[0m\n\u001B[0;32m     41\u001B[0m     backend \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKERAS_BACKEND\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m backend \u001B[38;5;129;01mand\u001B[39;00m backend \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 43\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     44\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen running Keras 2, the `KERAS_BACKEND` environment variable \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     45\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmust either be unset or `\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`. Received: `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     46\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo set another backend, please install Keras 3. See \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     47\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/keras-team/keras-nlp#installation\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     48\u001B[0m         )\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mkeras_3\u001B[39m():\n\u001B[0;32m     52\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check if Keras 3 is being used.\"\"\"\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: When running Keras 2, the `KERAS_BACKEND` environment variable must either be unset or `'tensorflow'`. Received: `torch`. To set another backend, please install Keras 3. See https://github.com/keras-team/keras-nlp#installation"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras_core as keras \n",
    "import keras_core.backend as K\n",
    "\n",
    "\n",
    "# import jax\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4785be",
   "metadata": {
    "papermill": {
     "duration": 0.010039,
     "end_time": "2023-11-03T11:08:49.632281",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.622242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f19b9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.654342Z",
     "iopub.status.busy": "2023-11-03T11:08:49.653755Z",
     "iopub.status.idle": "2023-11-03T11:08:49.659557Z",
     "shell.execute_reply": "2023-11-03T11:08:49.658653Z"
    },
    "papermill": {
     "duration": 0.019033,
     "end_time": "2023-11-03T11:08:49.661570",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.642537",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T06:19:33.187256900Z",
     "start_time": "2023-12-09T06:19:33.174368400Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"JAX:\", jax.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ed4eb",
   "metadata": {
    "papermill": {
     "duration": 0.010081,
     "end_time": "2023-11-03T11:08:49.682148",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.672067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ⚙️ | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfdaf7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.704337Z",
     "iopub.status.busy": "2023-11-03T11:08:49.703669Z",
     "iopub.status.idle": "2023-11-03T11:08:49.709506Z",
     "shell.execute_reply": "2023-11-03T11:08:49.708674Z"
    },
    "papermill": {
     "duration": 0.018903,
     "end_time": "2023-11-03T11:08:49.711315",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.692412",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.179251900Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # TEST_PATH = './kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv'\n",
    "    TEST_PATH = './kaggle/input/argugpt/argugpt.csv'\n",
    "    VACAB_PATH = './kaggle/Model/keras-nlp-deberta-v3-base-en-vocab-ds/vocab.spm'\n",
    "    CKPT_PATH = \"./kaggle/working/\"  # Name of pretrained models\n",
    "    num_of_dataset = 1000 # Num of test dataset\n",
    "    verbose = 0  # Verbosity\n",
    "    device = 'GPU'  # Device\n",
    "    seed = 42  # Random seed\n",
    "    batch_size = 10  # Batch size\n",
    "    drop_remainder = True  # Drop incomplete batches\n",
    "    sequence_length = 200  # Input sequence length\n",
    "    class_names = ['real','fake']  # Class names [A, B, C, D, E]\n",
    "    num_classes = len(class_names)  # Number of classes\n",
    "    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n",
    "    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n",
    "    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613197e",
   "metadata": {
    "papermill": {
     "duration": 0.009903,
     "end_time": "2023-11-03T11:08:49.731571",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.721668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ♻️ | Reproducibility \n",
    "Sets value for random seed to produce similar result in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0bae00",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.753146Z",
     "iopub.status.busy": "2023-11-03T11:08:49.752841Z",
     "iopub.status.idle": "2023-11-03T11:08:49.760601Z",
     "shell.execute_reply": "2023-11-03T11:08:49.759893Z"
    },
    "papermill": {
     "duration": 0.020701,
     "end_time": "2023-11-03T11:08:49.762469",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.741768",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.183255200Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49606d31",
   "metadata": {
    "papermill": {
     "duration": 0.009993,
     "end_time": "2023-11-03T11:08:49.782764",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.772771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 💾 | Hardware\n",
    "Following codes automatically detects hardware (TPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e7d57",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.804918Z",
     "iopub.status.busy": "2023-11-03T11:08:49.804604Z",
     "iopub.status.idle": "2023-11-03T11:08:49.811913Z",
     "shell.execute_reply": "2023-11-03T11:08:49.811096Z"
    },
    "papermill": {
     "duration": 0.020656,
     "end_time": "2023-11-03T11:08:49.813818",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.793162",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T06:19:33.227251400Z",
     "start_time": "2023-12-09T06:19:33.187256900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"Detect and intializes GPU/TPU automatically\"\n",
    "    try:\n",
    "        # Connect to TPU\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n",
    "        # Set TPU strategy\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
    "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
    "        device=CFG.device\n",
    "    except:\n",
    "        # If TPU is not available, detect GPUs\n",
    "        gpus = tf.config.list_logical_devices('GPU')\n",
    "        ngpu = len(gpus)\n",
    "         # Check number of GPUs\n",
    "        if ngpu:\n",
    "            # Set GPU strategy\n",
    "            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
    "            # Print GPU details\n",
    "            print(\"> Running on GPU\", end=' | ')\n",
    "            print(\"Num of GPUs: \", ngpu)\n",
    "            device='GPU'\n",
    "        else:\n",
    "            # If no GPUs are available, use CPU\n",
    "            print(\"> Running on CPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            device='CPU'\n",
    "    return strategy, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0f73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.836104Z",
     "iopub.status.busy": "2023-11-03T11:08:49.835219Z",
     "iopub.status.idle": "2023-11-03T11:08:54.677299Z",
     "shell.execute_reply": "2023-11-03T11:08:54.676216Z"
    },
    "papermill": {
     "duration": 4.855228,
     "end_time": "2023-11-03T11:08:54.679293",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.824065",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.191251500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize GPU/TPU/TPU-VM\n",
    "strategy, CFG.device = get_device()\n",
    "CFG.replicas = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090d5db",
   "metadata": {
    "papermill": {
     "duration": 0.010473,
     "end_time": "2023-11-03T11:08:54.700467",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.689994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📁 | Dataset Path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba01642",
   "metadata": {
    "papermill": {
     "duration": 0.00999,
     "end_time": "2023-11-03T11:08:54.748096",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.738106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📖 | Meta Data \n",
    "* `{test|train}_essays.csv`\n",
    "    * `id` - A unique identifier for each essay.\n",
    "    * `prompt_id` - Identifies the prompt the essay was written in response to.\n",
    "    * `text` - The essay text itself.\n",
    "    * `generated` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv.\n",
    "* **sample_submission.csv** - is the valid sample submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb67d6",
   "metadata": {
    "papermill": {
     "duration": 0.009916,
     "end_time": "2023-11-03T11:08:54.768279",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.758363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69dd6aa",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:54.790159Z",
     "iopub.status.busy": "2023-11-03T11:08:54.789627Z",
     "iopub.status.idle": "2023-11-03T11:08:54.816082Z",
     "shell.execute_reply": "2023-11-03T11:08:54.815167Z"
    },
    "papermill": {
     "duration": 0.039582,
     "end_time": "2023-11-03T11:08:54.818058",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.778476",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.196254900Z"
    }
   },
   "outputs": [],
   "source": [
    "ext_df1 = pd.read_csv(CFG.TEST_PATH)  # Read CSV file into a DataFrame\n",
    "ext_df1 = ext_df1[['id', 'text']]\n",
    "\n",
    "# test_df = pd.concat([\n",
    "#     ext_df1[ext_df1.label==0].sample(CFG.num_of_dataset//2),\n",
    "#     ext_df1[ext_df1.label==1].sample(CFG.num_of_dataset//2)\n",
    "# ])\n",
    "test_df = ext_df1.sample(1000)\n",
    "test_df['label'] = 1\n",
    "\n",
    "# Display information about the train data\n",
    "print(\"# Test Data: {:,}\".format(len(test_df)))\n",
    "print(\"# Sample:\")\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cddd0",
   "metadata": {
    "papermill": {
     "duration": 0.010564,
     "end_time": "2023-11-03T11:08:54.839359",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.828795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🍽️ | Preprocessing\n",
    "\n",
    "**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n",
    "\n",
    "**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n",
    "\n",
    "Explore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n",
    "- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cf143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:54.908622Z",
     "iopub.status.busy": "2023-11-03T11:08:54.908259Z",
     "iopub.status.idle": "2023-11-03T11:08:55.634837Z",
     "shell.execute_reply": "2023-11-03T11:08:55.633861Z"
    },
    "papermill": {
     "duration": 0.741063,
     "end_time": "2023-11-03T11:08:55.637326",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.896263",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.201255400Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer= keras_nlp.models.DebertaV3Tokenizer(CFG.VACAB_PATH)\n",
    "preprocessor= keras_nlp.models.DebertaV3Preprocessor(tokenizer, sequence_length=CFG.sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4133aa",
   "metadata": {
    "papermill": {
     "duration": 0.01051,
     "end_time": "2023-11-03T11:08:55.658822",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.648312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d1e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:55.681229Z",
     "iopub.status.busy": "2023-11-03T11:08:55.680879Z",
     "iopub.status.idle": "2023-11-03T11:08:55.967881Z",
     "shell.execute_reply": "2023-11-03T11:08:55.966667Z"
    },
    "papermill": {
     "duration": 0.300737,
     "end_time": "2023-11-03T11:08:55.970130",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.669393",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.204251200Z"
    }
   },
   "outputs": [],
   "source": [
    "outs = preprocessor(test_df.text.iloc[0])  # Process options for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924c02d",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2023-11-03T11:08:55.992833",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.981216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf5fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.015458Z",
     "iopub.status.busy": "2023-11-03T11:08:56.015143Z",
     "iopub.status.idle": "2023-11-03T11:08:56.019857Z",
     "shell.execute_reply": "2023-11-03T11:08:56.019001Z"
    },
    "papermill": {
     "duration": 0.018277,
     "end_time": "2023-11-03T11:08:56.021784",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.003507",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.207254Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebaaa0",
   "metadata": {
    "papermill": {
     "duration": 0.010385,
     "end_time": "2023-11-03T11:08:56.042774",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.032389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🍚 | DataLoader\n",
    "\n",
    "The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n",
    "\n",
    "To learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105f6fd",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.065193Z",
     "iopub.status.busy": "2023-11-03T11:08:56.064859Z",
     "iopub.status.idle": "2023-11-03T11:08:56.072439Z",
     "shell.execute_reply": "2023-11-03T11:08:56.071607Z"
    },
    "papermill": {
     "duration": 0.021202,
     "end_time": "2023-11-03T11:08:56.074442",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.053240",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.211258800Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=False, drop_remainder=True,\n",
    "                  augment=False, repeat=False, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=5))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d96ee",
   "metadata": {
    "papermill": {
     "duration": 0.010464,
     "end_time": "2023-11-03T11:08:56.095644",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.085180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fetch Train/test Dataset\n",
    "\n",
    "The function below generates the training and testation datasets for a given fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391e11a",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.118474Z",
     "iopub.status.busy": "2023-11-03T11:08:56.118153Z",
     "iopub.status.idle": "2023-11-03T11:08:56.123377Z",
     "shell.execute_reply": "2023-11-03T11:08:56.122518Z"
    },
    "papermill": {
     "duration": 0.018815,
     "end_time": "2023-11-03T11:08:56.125253",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.106438",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.214251500Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_dataset(test_df):\n",
    "    test_texts = test_df.text.tolist()  # Extract testation texts\n",
    "    \n",
    "    # Build testation dataset\n",
    "    test_ds = build_dataset(test_texts, labels=None,\n",
    "                             batch_size=min(CFG.batch_size*CFG.replicas, len(test_df)), cache=False,\n",
    "                             shuffle=False, drop_remainder=False, repeat=False)\n",
    "    \n",
    "    return test_ds  # Return datasets and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43b0d2",
   "metadata": {
    "papermill": {
     "duration": 0.010779,
     "end_time": "2023-11-03T11:08:56.146601",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.135822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🤖 | Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146efed6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.169205Z",
     "iopub.status.busy": "2023-11-03T11:08:56.168866Z",
     "iopub.status.idle": "2023-11-03T11:08:56.174359Z",
     "shell.execute_reply": "2023-11-03T11:08:56.173500Z"
    },
    "papermill": {
     "duration": 0.018937,
     "end_time": "2023-11-03T11:08:56.176215",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.157278",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.216249900Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Create a DebertaV3Classifier model\n",
    "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "        CFG.preset,\n",
    "        load_weights=False,\n",
    "        preprocessor=None,\n",
    "        num_classes=1 # one output per one option, for five options total 5 outputs\n",
    "    )\n",
    "    inputs = classifier.input\n",
    "    logits = classifier(inputs)\n",
    "        \n",
    "    # Compute final output\n",
    "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949fa675",
   "metadata": {
    "papermill": {
     "duration": 0.010495,
     "end_time": "2023-11-03T11:08:56.197329",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.186834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ckpt processing\n",
    "For some reason, `keras.models.load_model` requires write access as `/kaggle/input` doesn't have that access it throws error. Workaround is to simply copy the `ckpts` to other directory then load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4bec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.220194Z",
     "iopub.status.busy": "2023-11-03T11:08:56.219858Z",
     "iopub.status.idle": "2023-11-03T11:09:33.927801Z",
     "shell.execute_reply": "2023-11-03T11:09:33.926644Z"
    },
    "papermill": {
     "duration": 37.732553,
     "end_time": "2023-11-03T11:09:33.940839",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.208286",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.218256300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the checkpoint directory and name\n",
    "CKPT_PATH = CFG.CKPT_PATH\n",
    "# ckpt_name = 'daigt-kerasnlp-ckpt'\n",
    "\n",
    "# Copy the checkpoints to a new directory in the /kaggle directory\n",
    "# !cp -r {CKPT_PATH} /kaggle/{ckpt_name}\n",
    "\n",
    "# List all the checkpoint paths in the new directory\n",
    "# new_ckpt_dir = f\"/kaggle/{ckpt_name}\"\n",
    "new_ckpt_dir = CKPT_PATH\n",
    "ckpt_paths = glob(os.path.join(new_ckpt_dir, '*.keras'))\n",
    "\n",
    "print(\"Total CKPT:\", len(ckpt_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bbff4",
   "metadata": {
    "papermill": {
     "duration": 0.011346,
     "end_time": "2023-11-03T11:09:33.963480",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.952134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧪 | Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47fce8c",
   "metadata": {
    "papermill": {
     "duration": 0.010664,
     "end_time": "2023-11-03T11:09:33.985041",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.974377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6145f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:09:34.008721Z",
     "iopub.status.busy": "2023-11-03T11:09:34.008347Z",
     "iopub.status.idle": "2023-11-03T11:17:15.136923Z",
     "shell.execute_reply": "2023-11-03T11:17:15.136019Z"
    },
    "papermill": {
     "duration": 461.143679,
     "end_time": "2023-11-03T11:17:15.139776",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.996097",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.220251200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an array to store predictions for each fold\n",
    "fold_preds = np.zeros(shape=(len(test_df),), dtype='float32')\n",
    "\n",
    "# # Build model\n",
    "# model = build_model()\n",
    "\n",
    "# Iterate through each checkpoint path\n",
    "for ckpt_path in tqdm(ckpt_paths):\n",
    "    # Load the pre-trained model from the checkpoint\n",
    "    print(ckpt_path)\n",
    "    model = keras.models.load_model(\n",
    "        ckpt_path,\n",
    "        compile=False,\n",
    "    )\n",
    "#     model.load_weights(ckpt_path)\n",
    "    \n",
    "    # Get the test dataset\n",
    "    test_ds = get_test_dataset(test_df)\n",
    "    \n",
    "    # Generate predictions using the model\n",
    "    preds = model.predict(\n",
    "        test_ds,\n",
    "        batch_size=min(CFG.batch_size * CFG.replicas * 2, len(test_df)),  # Set batch size\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Add predictions to fold_preds and average over checkpoints\n",
    "    fold_preds += preds.squeeze() / len(ckpt_paths)\n",
    "    \n",
    "    # Clean up by deleting the model and collecting garbage\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de9ef7",
   "metadata": {
    "papermill": {
     "duration": 0.011215,
     "end_time": "2023-11-03T11:17:15.162809",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.151594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613b36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:17:15.187228Z",
     "iopub.status.busy": "2023-11-03T11:17:15.186591Z",
     "iopub.status.idle": "2023-11-03T11:17:15.193551Z",
     "shell.execute_reply": "2023-11-03T11:17:15.192694Z"
    },
    "papermill": {
     "duration": 0.021846,
     "end_time": "2023-11-03T11:17:15.195823",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.173977",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.222251600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Format predictions and true answers\n",
    "pred_answers = (fold_preds > 0.5).astype(int).squeeze()\n",
    "print(pred_answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check 5 Predictions\n",
    "print(\"# Predictions\\n\")\n",
    "for i in range(5):\n",
    "    row = test_df.iloc[i]\n",
    "    text  = row.text\n",
    "    pred_answer = CFG.label2name[pred_answers[i]]\n",
    "    print(f\"❓ Text {i+1}:\\n{text}\\n\")\n",
    "    print(f\"🤖 Predicted: {pred_answer}\\n\")\n",
    "    print(\"-\"*90, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.224253200Z"
    }
   },
   "id": "8abda16826ff3db6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(fold_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.226255300Z"
    }
   },
   "id": "2a810999230dee0b"
  },
  {
   "cell_type": "markdown",
   "id": "243c4613",
   "metadata": {
    "papermill": {
     "duration": 0.011218,
     "end_time": "2023-11-03T11:17:15.218817",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.207599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📮 | Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1359dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:17:15.242714Z",
     "iopub.status.busy": "2023-11-03T11:17:15.242463Z",
     "iopub.status.idle": "2023-11-03T11:17:15.264108Z",
     "shell.execute_reply": "2023-11-03T11:17:15.263181Z"
    },
    "papermill": {
     "duration": 0.035702,
     "end_time": "2023-11-03T11:17:15.265937",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.230235",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T06:19:33.248262100Z",
     "start_time": "2023-12-09T06:19:33.229256500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the submission\n",
    "sub_df = test_df.copy()\n",
    "\n",
    "# Add the formatted predictions to the submission DataFrame\n",
    "sub_df[\"pred_prob\"] = fold_preds.squeeze()\n",
    "sub_df[\"pred_label\"] = pred_answers\n",
    "sub_df[\"correct\"] = sub_df[\"pred_label\"] == sub_df[\"label\"]\n",
    "\n",
    "# Display the first 2 rows of the submission DataFrame\n",
    "sub_df.head(2)\n",
    "\n",
    "# Display Acc\n",
    "total_cor = sub_df[\"correct\"].sum()\n",
    "print(f'Total Correct: {total_cor} / {len(sub_df)}')\n",
    "print(f'Acc: {(total_cor * 100) / len(sub_df):.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T06:19:33.232255900Z"
    }
   },
   "id": "8857cd30ac69ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 571.794825,
   "end_time": "2023-11-03T11:17:18.707885",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-03T11:07:46.913060",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16bae7a0a18f4c02b4c3da8e19f2245d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cffc34a76088491e9ce64b26c928f515",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_adb3d6ece1f247a0bc75f96cde5824fb",
       "value": 3.0
      }
     },
     "18d9748054464aa79345e251a618a993": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a40012713ee4900a539fd624a9f490a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4fef6e06395440228abc9c0ed870af81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_67a9a1a155544b058918db44bcf0ac2c",
        "IPY_MODEL_16bae7a0a18f4c02b4c3da8e19f2245d",
        "IPY_MODEL_8c55f9743fa745d0850cfb7a0caca1e5"
       ],
       "layout": "IPY_MODEL_d9f9892cfec647b1a6e667600470d307"
      }
     },
     "6317eb64a6d84c1385a2f74d0c58b9bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67a9a1a155544b058918db44bcf0ac2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d185c8d4593f4fb29d83ddd5147aa6c9",
       "placeholder": "​",
       "style": "IPY_MODEL_3a40012713ee4900a539fd624a9f490a",
       "value": "100%"
      }
     },
     "8c55f9743fa745d0850cfb7a0caca1e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6317eb64a6d84c1385a2f74d0c58b9bb",
       "placeholder": "​",
       "style": "IPY_MODEL_18d9748054464aa79345e251a618a993",
       "value": " 3/3 [07:41&lt;00:00, 152.83s/it]"
      }
     },
     "adb3d6ece1f247a0bc75f96cde5824fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cffc34a76088491e9ce64b26c928f515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d185c8d4593f4fb29d83ddd5147aa6c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9f9892cfec647b1a6e667600470d307": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
