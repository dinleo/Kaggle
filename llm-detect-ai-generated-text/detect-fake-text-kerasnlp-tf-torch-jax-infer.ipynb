{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc84ed0",
   "metadata": {
    "papermill": {
     "duration": 0.009968,
     "end_time": "2023-11-03T11:07:50.362283",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.352315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM - Detect AI Generated Text\n",
    "> Identify which essay was written by a large language model\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/36858976/279902422-b365f6ef-ef01-49ac-af7f-0bc2ca3ba835.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747d2c5",
   "metadata": {
    "papermill": {
     "duration": 0.009061,
     "end_time": "2023-11-03T11:07:50.381082",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.372021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üéØ | Motivation\n",
    "\n",
    "* In this notebook, we will demonstrate the usage of the multi-backend capabilities of `KerasCore` and `KerasNLP` for the **Detect Fake Text** infernece."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cffedf",
   "metadata": {
    "papermill": {
     "duration": 0.008952,
     "end_time": "2023-11-03T11:07:50.399317",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.390365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìì | Notebooks\n",
    "\n",
    "* Train: [Detect Fake Text: KerasNLP [TF/Torch/JAX][Train]](https://www.kaggle.com/code/awsaf49/detect-fake-text-kerasnlp-tf-torch-jax-train)\n",
    "* Infer: [Detect Fake Text: KerasNLP [TF/Torch/JAX][Infer]](https://www.kaggle.com/code/awsaf49/detect-fake-text-kerasnlp-tf-torch-jax-infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5c601",
   "metadata": {
    "papermill": {
     "duration": 0.008928,
     "end_time": "2023-11-03T11:07:50.417435",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.408507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üõ† | Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdad111e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-03T11:07:50.438042Z",
     "iopub.status.busy": "2023-11-03T11:07:50.437124Z",
     "iopub.status.idle": "2023-11-03T11:08:37.468269Z",
     "shell.execute_reply": "2023-11-03T11:08:37.467172Z"
    },
    "papermill": {
     "duration": 47.043954,
     "end_time": "2023-11-03T11:08:37.470635",
     "exception": false,
     "start_time": "2023-11-03T11:07:50.426681",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-15T06:25:30.576857100Z",
     "start_time": "2023-11-15T06:25:27.208348300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\kaggle\\input\\llm-science-exam-lib-ds\\keras_core-0.1.7-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement '/kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.7-py3-none-any.whl' looks like a filename, but the file does not exist\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\kaggle\\\\input\\\\llm-science-exam-lib-ds\\\\keras_core-0.1.7-py3-none-any.whl'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\kaggle\\input\\llm-science-exam-lib-ds\\keras_nlp-0.6.2-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement '/kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.2-py3-none-any.whl' looks like a filename, but the file does not exist\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\kaggle\\\\input\\\\llm-science-exam-lib-ds\\\\keras_nlp-0.6.2-py3-none-any.whl'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.7-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.2-py3-none-any.whl --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a5988",
   "metadata": {
    "papermill": {
     "duration": 0.010165,
     "end_time": "2023-11-03T11:08:37.491304",
     "exception": false,
     "start_time": "2023-11-03T11:08:37.481139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6edb7c8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:37.512852Z",
     "iopub.status.busy": "2023-11-03T11:08:37.512540Z",
     "iopub.status.idle": "2023-11-03T11:08:49.609104Z",
     "shell.execute_reply": "2023-11-03T11:08:49.608286Z"
    },
    "papermill": {
     "duration": 12.110162,
     "end_time": "2023-11-03T11:08:49.611447",
     "exception": false,
     "start_time": "2023-11-03T11:08:37.501285",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T07:59:28.288094500Z",
     "start_time": "2023-11-16T07:59:18.382440100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras_core as keras \n",
    "import keras_core.backend as K\n",
    "\n",
    "\n",
    "# import jax\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4785be",
   "metadata": {
    "papermill": {
     "duration": 0.010039,
     "end_time": "2023-11-03T11:08:49.632281",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.622242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378f19b9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.654342Z",
     "iopub.status.busy": "2023-11-03T11:08:49.653755Z",
     "iopub.status.idle": "2023-11-03T11:08:49.659557Z",
     "shell.execute_reply": "2023-11-03T11:08:49.658653Z"
    },
    "papermill": {
     "duration": 0.019033,
     "end_time": "2023-11-03T11:08:49.661570",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.642537",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T07:59:28.292094300Z",
     "start_time": "2023-11-16T07:59:28.278094600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.1\n",
      "Keras: 0.1.7\n",
      "KerasNLP: 0.6.3\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"JAX:\", jax.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ed4eb",
   "metadata": {
    "papermill": {
     "duration": 0.010081,
     "end_time": "2023-11-03T11:08:49.682148",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.672067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚öôÔ∏è | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cfdaf7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.704337Z",
     "iopub.status.busy": "2023-11-03T11:08:49.703669Z",
     "iopub.status.idle": "2023-11-03T11:08:49.709506Z",
     "shell.execute_reply": "2023-11-03T11:08:49.708674Z"
    },
    "papermill": {
     "duration": 0.018903,
     "end_time": "2023-11-03T11:08:49.711315",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.692412",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T07:59:35.282608200Z",
     "start_time": "2023-11-16T07:59:35.263438100Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TEST_PATH = '../kaggle/input/llm-detect-ai-generated-text/test_essays.csv'\n",
    "    VACAB_PATH = '../kaggle/Model/keras-nlp-deberta-v3-base-en-vocab-ds/vocab.spm'\n",
    "    CKPT_PATH = \"../kaggle/Model/daigt-kerasnlp-ckpt\"  # Name of pretrained models\n",
    "    verbose = 0  # Verbosity\n",
    "    device = 'GPU'  # Device\n",
    "    seed = 42  # Random seed\n",
    "    batch_size = 6  # Batch size\n",
    "    drop_remainder = True  # Drop incomplete batches\n",
    "    sequence_length = 200  # Input sequence length\n",
    "    class_names = ['real','fake']  # Class names [A, B, C, D, E]\n",
    "    num_classes = len(class_names)  # Number of classes\n",
    "    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n",
    "    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n",
    "    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613197e",
   "metadata": {
    "papermill": {
     "duration": 0.009903,
     "end_time": "2023-11-03T11:08:49.731571",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.721668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚ôªÔ∏è | Reproducibility \n",
    "Sets value for random seed to produce similar result in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0bae00",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.753146Z",
     "iopub.status.busy": "2023-11-03T11:08:49.752841Z",
     "iopub.status.idle": "2023-11-03T11:08:49.760601Z",
     "shell.execute_reply": "2023-11-03T11:08:49.759893Z"
    },
    "papermill": {
     "duration": 0.020701,
     "end_time": "2023-11-03T11:08:49.762469",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.741768",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T07:59:37.900394700Z",
     "start_time": "2023-11-16T07:59:37.866396400Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49606d31",
   "metadata": {
    "papermill": {
     "duration": 0.009993,
     "end_time": "2023-11-03T11:08:49.782764",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.772771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üíæ | Hardware\n",
    "Following codes automatically detects hardware (TPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16e7d57",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.804918Z",
     "iopub.status.busy": "2023-11-03T11:08:49.804604Z",
     "iopub.status.idle": "2023-11-03T11:08:49.811913Z",
     "shell.execute_reply": "2023-11-03T11:08:49.811096Z"
    },
    "papermill": {
     "duration": 0.020656,
     "end_time": "2023-11-03T11:08:49.813818",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.793162",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T07:59:39.747069700Z",
     "start_time": "2023-11-16T07:59:39.711071600Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"Detect and intializes GPU/TPU automatically\"\n",
    "    try:\n",
    "        # Connect to TPU\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n",
    "        # Set TPU strategy\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
    "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
    "        device=CFG.device\n",
    "    except:\n",
    "        # If TPU is not available, detect GPUs\n",
    "        gpus = tf.config.list_logical_devices('GPU')\n",
    "        ngpu = len(gpus)\n",
    "         # Check number of GPUs\n",
    "        if ngpu:\n",
    "            # Set GPU strategy\n",
    "            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
    "            # Print GPU details\n",
    "            print(\"> Running on GPU\", end=' | ')\n",
    "            print(\"Num of GPUs: \", ngpu)\n",
    "            device='GPU'\n",
    "        else:\n",
    "            # If no GPUs are available, use CPU\n",
    "            print(\"> Running on CPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            device='CPU'\n",
    "    return strategy, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e0f73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:49.836104Z",
     "iopub.status.busy": "2023-11-03T11:08:49.835219Z",
     "iopub.status.idle": "2023-11-03T11:08:54.677299Z",
     "shell.execute_reply": "2023-11-03T11:08:54.676216Z"
    },
    "papermill": {
     "duration": 4.855228,
     "end_time": "2023-11-03T11:08:54.679293",
     "exception": false,
     "start_time": "2023-11-03T11:08:49.824065",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T07:59:41.674751300Z",
     "start_time": "2023-11-16T07:59:40.150255300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPU/TPU/TPU-VM\n",
    "strategy, CFG.device = get_device()\n",
    "CFG.replicas = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090d5db",
   "metadata": {
    "papermill": {
     "duration": 0.010473,
     "end_time": "2023-11-03T11:08:54.700467",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.689994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÅ | Dataset Path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba01642",
   "metadata": {
    "papermill": {
     "duration": 0.00999,
     "end_time": "2023-11-03T11:08:54.748096",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.738106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìñ | Meta Data \n",
    "* `{test|train}_essays.csv`\n",
    "    * `id` - A unique identifier for each essay.\n",
    "    * `prompt_id` - Identifies the prompt the essay was written in response to.\n",
    "    * `text` - The essay text itself.\n",
    "    * `generated` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv.\n",
    "* **sample_submission.csv** - is the valid sample submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb67d6",
   "metadata": {
    "papermill": {
     "duration": 0.009916,
     "end_time": "2023-11-03T11:08:54.768279",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.758363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69dd6aa",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:54.790159Z",
     "iopub.status.busy": "2023-11-03T11:08:54.789627Z",
     "iopub.status.idle": "2023-11-03T11:08:54.816082Z",
     "shell.execute_reply": "2023-11-03T11:08:54.815167Z"
    },
    "papermill": {
     "duration": 0.039582,
     "end_time": "2023-11-03T11:08:54.818058",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.778476",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:08.189307400Z",
     "start_time": "2023-11-16T08:00:08.119307500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Data: 3\n",
      "# Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": "         id  prompt_id          text\n0  0000aaaa          2  Aaa bbb ccc.\n1  1111bbbb          3  Bbb ccc ddd.",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>2</td>\n      <td>Aaa bbb ccc.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1111bbbb</td>\n      <td>3</td>\n      <td>Bbb ccc ddd.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(CFG.TEST_PATH)  # Read CSV file into a DataFrame\n",
    "\n",
    "# Display information about the train data\n",
    "print(\"# Test Data: {:,}\".format(len(test_df)))\n",
    "print(\"# Sample:\")\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cddd0",
   "metadata": {
    "papermill": {
     "duration": 0.010564,
     "end_time": "2023-11-03T11:08:54.839359",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.828795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üçΩÔ∏è | Preprocessing\n",
    "\n",
    "**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n",
    "\n",
    "**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n",
    "\n",
    "Explore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n",
    "- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9cf143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:54.908622Z",
     "iopub.status.busy": "2023-11-03T11:08:54.908259Z",
     "iopub.status.idle": "2023-11-03T11:08:55.634837Z",
     "shell.execute_reply": "2023-11-03T11:08:55.633861Z"
    },
    "papermill": {
     "duration": 0.741063,
     "end_time": "2023-11-03T11:08:55.637326",
     "exception": false,
     "start_time": "2023-11-03T11:08:54.896263",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:17.925155700Z",
     "start_time": "2023-11-16T08:00:17.141152300Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer= keras_nlp.models.DebertaV3Tokenizer(CFG.VACAB_PATH)\n",
    "preprocessor= keras_nlp.models.DebertaV3Preprocessor(tokenizer, sequence_length=CFG.sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4133aa",
   "metadata": {
    "papermill": {
     "duration": 0.01051,
     "end_time": "2023-11-03T11:08:55.658822",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.648312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601d1e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:55.681229Z",
     "iopub.status.busy": "2023-11-03T11:08:55.680879Z",
     "iopub.status.idle": "2023-11-03T11:08:55.967881Z",
     "shell.execute_reply": "2023-11-03T11:08:55.966667Z"
    },
    "papermill": {
     "duration": 0.300737,
     "end_time": "2023-11-03T11:08:55.970130",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.669393",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:20.406293400Z",
     "start_time": "2023-11-16T08:00:20.160295700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : torch.Size([200])\n",
      "padding_mask : torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "outs = preprocessor(test_df.text.iloc[0])  # Process options for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924c02d",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2023-11-03T11:08:55.992833",
     "exception": false,
     "start_time": "2023-11-03T11:08:55.981216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52bf5fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.015458Z",
     "iopub.status.busy": "2023-11-03T11:08:56.015143Z",
     "iopub.status.idle": "2023-11-03T11:08:56.019857Z",
     "shell.execute_reply": "2023-11-03T11:08:56.019001Z"
    },
    "papermill": {
     "duration": 0.018277,
     "end_time": "2023-11-03T11:08:56.021784",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.003507",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:23.454042800Z",
     "start_time": "2023-11-16T08:00:23.422787300Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebaaa0",
   "metadata": {
    "papermill": {
     "duration": 0.010385,
     "end_time": "2023-11-03T11:08:56.042774",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.032389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üçö | DataLoader\n",
    "\n",
    "The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n",
    "\n",
    "To learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f105f6fd",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.065193Z",
     "iopub.status.busy": "2023-11-03T11:08:56.064859Z",
     "iopub.status.idle": "2023-11-03T11:08:56.072439Z",
     "shell.execute_reply": "2023-11-03T11:08:56.071607Z"
    },
    "papermill": {
     "duration": 0.021202,
     "end_time": "2023-11-03T11:08:56.074442",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.053240",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:28.288981500Z",
     "start_time": "2023-11-16T08:00:28.256951200Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=False, drop_remainder=True,\n",
    "                  augment=False, repeat=False, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=5))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d96ee",
   "metadata": {
    "papermill": {
     "duration": 0.010464,
     "end_time": "2023-11-03T11:08:56.095644",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.085180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fetch Train/test Dataset\n",
    "\n",
    "The function below generates the training and testation datasets for a given fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c391e11a",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.118474Z",
     "iopub.status.busy": "2023-11-03T11:08:56.118153Z",
     "iopub.status.idle": "2023-11-03T11:08:56.123377Z",
     "shell.execute_reply": "2023-11-03T11:08:56.122518Z"
    },
    "papermill": {
     "duration": 0.018815,
     "end_time": "2023-11-03T11:08:56.125253",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.106438",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:32.558924300Z",
     "start_time": "2023-11-16T08:00:32.526923Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_dataset(test_df):\n",
    "    test_texts = test_df.text.tolist()  # Extract testation texts\n",
    "    \n",
    "    # Build testation dataset\n",
    "    test_ds = build_dataset(test_texts, labels=None,\n",
    "                             batch_size=min(CFG.batch_size*CFG.replicas, len(test_df)), cache=False,\n",
    "                             shuffle=False, drop_remainder=False, repeat=False)\n",
    "    \n",
    "    return test_ds  # Return datasets and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43b0d2",
   "metadata": {
    "papermill": {
     "duration": 0.010779,
     "end_time": "2023-11-03T11:08:56.146601",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.135822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ü§ñ | Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "146efed6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.169205Z",
     "iopub.status.busy": "2023-11-03T11:08:56.168866Z",
     "iopub.status.idle": "2023-11-03T11:08:56.174359Z",
     "shell.execute_reply": "2023-11-03T11:08:56.173500Z"
    },
    "papermill": {
     "duration": 0.018937,
     "end_time": "2023-11-03T11:08:56.176215",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.157278",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:00:40.144059300Z",
     "start_time": "2023-11-16T08:00:40.098466Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Create a DebertaV3Classifier model\n",
    "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "        CFG.preset,\n",
    "        load_weights=False,\n",
    "        preprocessor=None,\n",
    "        num_classes=1 # one output per one option, for five options total 5 outputs\n",
    "    )\n",
    "    inputs = classifier.input\n",
    "    logits = classifier(inputs)\n",
    "        \n",
    "    # Compute final output\n",
    "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949fa675",
   "metadata": {
    "papermill": {
     "duration": 0.010495,
     "end_time": "2023-11-03T11:08:56.197329",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.186834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ckpt processing\n",
    "For some reason, `keras.models.load_model` requires write access as `/kaggle/input` doesn't have that access it throws error. Workaround is to simply copy the `ckpts` to other directory then load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf4bec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:08:56.220194Z",
     "iopub.status.busy": "2023-11-03T11:08:56.219858Z",
     "iopub.status.idle": "2023-11-03T11:09:33.927801Z",
     "shell.execute_reply": "2023-11-03T11:09:33.926644Z"
    },
    "papermill": {
     "duration": 37.732553,
     "end_time": "2023-11-03T11:09:33.940839",
     "exception": false,
     "start_time": "2023-11-03T11:08:56.208286",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:01:17.118467200Z",
     "start_time": "2023-11-16T08:01:17.076464200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CKPT: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the checkpoint directory and name\n",
    "CKPT_PATH = CFG.CKPT_PATH\n",
    "# ckpt_name = 'daigt-kerasnlp-ckpt'\n",
    "\n",
    "# Copy the checkpoints to a new directory in the /kaggle directory\n",
    "# !cp -r {CKPT_PATH} /kaggle/{ckpt_name}\n",
    "\n",
    "# List all the checkpoint paths in the new directory\n",
    "# new_ckpt_dir = f\"/kaggle/{ckpt_name}\"\n",
    "new_ckpt_dir = CKPT_PATH\n",
    "ckpt_paths = glob(os.path.join(new_ckpt_dir, '*.keras'))\n",
    "\n",
    "print(\"Total CKPT:\", len(ckpt_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bbff4",
   "metadata": {
    "papermill": {
     "duration": 0.011346,
     "end_time": "2023-11-03T11:09:33.963480",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.952134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß™ | Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47fce8c",
   "metadata": {
    "papermill": {
     "duration": 0.010664,
     "end_time": "2023-11-03T11:09:33.985041",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.974377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a6145f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:09:34.008721Z",
     "iopub.status.busy": "2023-11-03T11:09:34.008347Z",
     "iopub.status.idle": "2023-11-03T11:17:15.136923Z",
     "shell.execute_reply": "2023-11-03T11:17:15.136019Z"
    },
    "papermill": {
     "duration": 461.143679,
     "end_time": "2023-11-03T11:17:15.139776",
     "exception": false,
     "start_time": "2023-11-03T11:09:33.996097",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-16T08:03:08.615105700Z",
     "start_time": "2023-11-16T08:01:27.916294100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0869f54afb06499c89efb558513478d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../kaggle/Model/daigt-kerasnlp-ckpt\\fold0.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_core\\src\\trainers\\trainer.py:166: UserWarning: `jit_compile` is not yet enabled for the PyTorch backend. Proceeding with `jit_compile=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dinle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras_core\\src\\saving\\serialization_lib.py:713: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize an array to store predictions for each fold\n",
    "fold_preds = np.zeros(shape=(len(test_df),), dtype='float32')\n",
    "\n",
    "# # Build model\n",
    "# model = build_model()\n",
    "\n",
    "# Iterate through each checkpoint path\n",
    "for ckpt_path in tqdm(ckpt_paths):\n",
    "    # Load the pre-trained model from the checkpoint\n",
    "    print(ckpt_path)\n",
    "    model = keras.models.load_model(\n",
    "        ckpt_path,\n",
    "        compile=False,\n",
    "    )\n",
    "#     model.load_weights(ckpt_path)\n",
    "    \n",
    "    # Get the test dataset\n",
    "    test_ds = get_test_dataset(test_df)\n",
    "    \n",
    "    # Generate predictions using the model\n",
    "    preds = model.predict(\n",
    "        test_ds,\n",
    "        batch_size=min(CFG.batch_size * CFG.replicas * 2, len(test_df)),  # Set batch size\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Add predictions to fold_preds and average over checkpoints\n",
    "    fold_preds += preds.squeeze() / len(ckpt_paths)\n",
    "    \n",
    "    # Clean up by deleting the model and collecting garbage\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de9ef7",
   "metadata": {
    "papermill": {
     "duration": 0.011215,
     "end_time": "2023-11-03T11:17:15.162809",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.151594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7613b36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:17:15.187228Z",
     "iopub.status.busy": "2023-11-03T11:17:15.186591Z",
     "iopub.status.idle": "2023-11-03T11:17:15.193551Z",
     "shell.execute_reply": "2023-11-03T11:17:15.192694Z"
    },
    "papermill": {
     "duration": 0.021846,
     "end_time": "2023-11-03T11:17:15.195823",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.173977",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-15T06:35:36.771560200Z",
     "start_time": "2023-11-15T06:35:36.753565900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1378,)\n"
     ]
    }
   ],
   "source": [
    "# Format predictions and true answers\n",
    "pred_answers = (fold_preds > 0.5).astype(int).squeeze()\n",
    "print(pred_answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions\n",
      "\n",
      "‚ùì Text 1:\n",
      "Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of cars might be a good thing to do.\n",
      "\n",
      "In like matter of this, article, \"In German Suburb, Life Goes On Without Cars,\" by Elizabeth Rosenthal states, how automobiles are the linchpin of suburbs, where middle class families from either Shanghai or Chicago tend to make their homes. Experts say how this is a huge impediment to current efforts to reduce greenhouse gas emissions from tailpipe. Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe...and up to 50 percent in some carintensive areas in the United States. Cars are the main reason for the greenhouse gas emissions because of a lot of people driving them around all the time getting where they need to go. Article, \"Paris bans driving due to smog,\" by Robert Duffer says, how Paris, after days of nearrecord pollution, enforced a partial driving ban to clear the air of the global city. It also says, how on Monday, motorist with evennumbered license plates were ordered to leave their cars at home or be fined a 22euro fine 31. The same order would be applied to oddnumbered plates the following day. Cars are the reason for polluting entire cities like Paris. This shows how bad cars can be because, of all the pollution that they can cause to an entire city.\n",
      "\n",
      "Likewise, in the article, \"Carfree day is spinning into a big hit in Bogota,\" by Andrew Selsky says, how programs that's set to spread to other countries, millions of Columbians hiked, biked, skated, or took the bus to work during a carfree day, leaving streets of this capital city eerily devoid of traffic jams. It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in the capital city of 7 million. People like the idea of having carfree days because, it allows them to lesson the pollution that cars put out of their exhaust from people driving all the time. The article also tells how parks and sports centers have bustled throughout the city uneven, pitted sidewalks have been replaced by broad, smooth sidewalks rushhour restrictions have dramatically cut traffic and new restaurants and upscale shopping districts have cropped up. Having no cars has been good for the country of Columbia because, it has aloud them to repair things that have needed repairs for a long time, traffic jams have gone down, and restaurants and shopping districts have popped up, all due to the fact of having less cars around.\n",
      "\n",
      "In conclusion, the use of less cars and having carfree days, have had a big impact on the environment of cities because, it is cutting down the air pollution that the cars have majorly polluted, it has aloud countries like Columbia to repair sidewalks, and cut down traffic jams. Limiting the use of cars would be a good thing for America. So we should limit the use of cars by maybe riding a bike, or maybe walking somewhere that isn't that far from you and doesn't need the use of a car to get you there. To me, limiting the use of cars might be a good thing to do.\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 2:\n",
      "Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, and other means of transportation make going from place to place easier and faster. However there's always a negative pollution. Although mobile transportation are a huge part of daily lives, we are endangering the Earth with harmful greenhouse gases, which could be suppressed.\n",
      "\n",
      "A small suburb community in Germany called Vauban, has started a \"carfree\" lifestyle. In this city, markets and stores are placed nearby homes, instead of being located by farend highways. Although Vauban is not completely carfree, 70% of Vauban families do not own cars Even a large 57% of families stated to have sold their cars to move to Vauban. Some families have even said to be less stressed depending on car transportation. Cars are responsible for about 12% of greenhouse gases, and can even be up to 50% in some carintensive areas in the United States.\n",
      "\n",
      "Another insight to reduced car zones brings Paris' incident with smog. Paris' officials created a system that would in fact lower smog rates. On Monday, the motorists with evennumbered license plates numbers would be ordered to leave their cars at home, or they would suffer a fine. Same rule would occur on Tuesday, except motorists with oddnumbered license plates were targeted with fines. Congestion, or traffic, was reduced by 60% after five days of intense smog. Diesel fuel played a huge part in this pollution, having the fact that 67% of vehicles in France are of Diesel fuel. The impact of the clearing of smog, resided in banning the Tuesday rule of odd license plates.\n",
      "\n",
      "Could you imagine a day without seeing a single car being used? This phenomenon occurs once a year in Bogota, Colombia. With the exception of buses and taxis being used, cars are to be left unattended for an entire day. Having a carfree day just once a year can even reduce the pollution slightly. The day without cars is part of a campaign that originated in Bogota in the mid 1990s. This campaign has renewed and constructed numerous bicycle paths and sidewalks all over the city. Parks and sports centers have also sprung from this campaign. Devoting your time to a carfree lifestyle has it's hassles, but in hindsight, it has it's benefits.\n",
      "\n",
      "To conclude, living a carfree lifestyle does not seem like a possibility in this day and age, however managing the use of cars and pollution is something every country should take time investing in. Think about how much of an impact it would be if everywhere worldwide would take part in airpollution reduction. Mobile transportation is lifestyle in a sense, and being dependent on cars or other means of transportation can impact the health of the Earth and even ourselves.\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 3:\n",
      "\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To understand rosenthal's perspective, it is easier to suggest that America's car usage is decreasing slowly. This isn't necessarily bad in the sense that it has certain positive effects. The advantages of limiting car usage includes an increase in security and health, along with a decrease in pollution and dependence.\n",
      "\n",
      "Firstly, when car usage is limited security and health is more likely to be guaranteed. The feeling of being secure is highly important to individuals everywhere. For example, many people in colombia used public transportation during a car free day \"leaving the streets of this capital city \", according to Andrew Selsky, \"eerily devoid of traffic jams\". The complications that stem from traffic jams end with a feeling of confidence. The plan to get from point A to B was more simple just a second ago. This complication in your personal plans leads you to become stressed as a feeling of doubt overcomes all thoughts. If car usage was limited, there would be a control on how much traffic accumulates thus minimizing chance of stress. As Heidrun Walter states \"when i had a car i was always tense. I'm much happier this way\". not only does car usage minimize conditions detrimental to health, it also enlarges your capacity for exercise. The main purpose of the car is to get someone from one place to another. when an important job takes over your personal life, it becomes difficult to do things most enjoyed in life. limits on car usage forces you to stay in shape. According to Andrew Selsky \"parks and sports centers also have bloomed throughout the city\". Less cars means healthier and natural situations. With parks and sport centers becoming more efficient, it becomes easier to find a more physically active population. Overall, less usage on cars minimizes stress and increases health.\n",
      "\n",
      "Secondly, limting car usage becomes beneficial to the environment. Now a days people have become annoyed with others who care so passionately about the environment. If you look behind their constant cries for action, there are solid facts. Yespollution is bad for the environment. Yes a bad envorment means unhealthy living. Yes cars are one of the main contributors to pollution in the environment. A pattern of less car usage, as Elisabeth Rosenthal states \"will have beneficial implications for carbon emissions and the environment\". The less use of cars, the less pollution in the environment. One must observe limiting car usage as an opportunity to create a cleaner world and better future. The effects of pollution in the environment is completley dangerous and we, the car users, are to blame.\n",
      "\n",
      "Additionally, it would lower the dependence on cars. Many people today find that their car is so useful. While it has many features and is a form of transportation, many do not figure what they would do if they did not have such a possesion. The development of people and their interaction with technology has left a wide gap between historic, natural ways and what is thought of as modern society. Being dependent is not always good for individuals. As david goldberg says \"all our development since world war II has been centered on the car, and that will have to change\". Many people could disagree and wonder why it is necessary to change our ways especially if we are so highly devloped. If being developed means being dependent on a harmful machine, then it could not be effective devlopment. According to Elisabeth Rosenthal \"cashstrapped americans could not afford new cars, and the unemployed were't going to work anyway\". Many people can't have the precious luxury of private transportation in the first place. Those who have had it have become distant to a more natural society. Peope have become so use to having cars that they have become oblivious to the significant effects. With limits on car usage , these effcts could be controlled.\n",
      "\n",
      "To conclude, the advantages of limiting car usage is an increase in health, along with a decrease in pollution, and less dependence on cars. limiting car usage is a positive way to enfore an organized and clean environment, and ensure health and security of those who live in it. This is one reason America can be reffered to as a succesful country. It is not that America has decreased use of vehicles, but the fact that they have done what is best for majority.\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 4:\n",
      "How often do you ride in a car? Do you drive a one or any other motor vehicle to work? The store? To the mall? Have you ever thought about how many people in the world do that exact same thing travel to every destination using a fuel powered motorvehicle. Not many people realize the intensive damage that they're doing when they turn their key in the ignition. What if you didn't drive to work today? If you're like any regular car user, the thought \"What?! I could never survive without my car!\" may run through your mind. It is possible though, to live without your main mean of transport. Just look at cities like cuban, Paris, and Bogota each one has in some way restricted their people's usage of cars and they actually enjoy it! If you limit your car usage, it can intern result in many advantages and benefits in yourself and in your community.\n",
      "\n",
      "A not so recognized benefit to giving up your car usage would be the positive consequences it has on your health. In source 1, Heidrun Walter states that \"When he had a car, he was always tense. He's much happier without it.\" Think about it, imagine all the angry road rage you experience while driving. That surely does not have a positive effect on your mood or health. Driving takes a copious amount of focus and mental activity, such as, trying to navigate, dealing with bad drivers, etc., that after a short period of time, you're stressed out and tired. In cities like New York and Paris, the population is high. This leads to congestion in the streets and excessive amounts of pollution. Warm layers of air, according to Robert Duffer in \"Paris bans driving due to smog,\" traps the car emissions. How is that healthy? He also states that Paris had to enforce a temporary driving ban after the pollution levels reached an all time record. After a few days of less driving the pollution went way down. Since people aren't driving, they have to find other means of transport. This could include walking, biking, or skating to destinations. Those are all physical excercises! Your body is getting to work out and you'll mentally feel fresher more than you would sitting in a car.\n",
      "\n",
      "Taking a break from driving also can help with the overall look of your city. Pollution doesn't cause the flowers to grow. It certainly doesn't smell nice. It sets a filter over the town and gives off a \"dirty\" vibe. With less driving, there is less nasty pollution being emitted, therefore leading to a cleaner community. In Elisabeth Rosenthal's article, \"In German Suburb, Life goes on Without Cars,\" she gives the good point that since there is a restriction on car and motor vehicle transportation, there is going to be more walkers. If you have tons of people taking the sidewalks instead of the roads, you might need a few more pathways and closer stores that are in walking distance. Andrew Selsky states that \"Parks and sports centers have bloomed throughout the city uneven pitted sidewalks have been replaced by broad, smooth sidewalks... and new restaurants and upscale shopping districts have cropped up.\" As stated previously, pollution is not benefiting the environment. Organizations such as the Envronmental Protection Agency in the U.S., are promoting \"car reduced\" communities, says Rosenthal. These communities have far less pollution and are much cleaner. Cities are also promoting this idea and are having days devoted to \"nocar driving.\" In Bogota, Colombia, they hold an anual \"carfree\" day where only buses and taxis are permitted. Any other drivers would be fined. Although fining someone for using a posession they own might ruffle some feathers, it did have a successful turn out and significantly reduced the \"smog.\" In conclusion, although the idea of giving up our precious automobiles for walking to our destination might sound impossible, it's not. Reducing our driving can lead to many benefits and advantages in our daily lives. These include an increase in health, an improved look to our cities, and an improved environment all around us.\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "‚ùì Text 5:\n",
      "Cars are a wonderful thing. They are perhaps one of the worlds greatest advancements and technologies. Cars get us from point a to point i. That is exactly what we want isnt it? We as humans want to get from one place to anther as fast as possiile. Cars are a suitaile to do that. They get us across the city in a matter of minutes. Much faster than anyhting else we have. A train isnt going to get me across the city as fast as my car is and neither is a puilic ius, iut those other forms of transportation just might ie the way to go. Don't get me wrong, cars are an aisolutly amazing thing iut, mayie they just cause way to much stress, and mayie they hurt our environment in ways that we don't think they will. With a ius or a train you do not have to worry aiout washing your car or getting frustrated when stuck in a iad traffic jam on I4. Also there is not as much pollution in air hurting our environment. You might not think so, iut there are many advantages to limiting our car usage.\n",
      "\n",
      "One advantage that not only humans would ienefit from, iut also plants and animals is that there would ie a lot less pollution in the air hurting out environment. Right now our cars give off gases that are extremely harmful towards our environment. These gases are called green house gases and come out of the exhaust pipes in our cars. Your car alone docent give off much gas iut collectively, our cars give off enormous amounts of gases. This is especially true in iig cities like France. In France, their pollution level was so high it was record ireaking. due to that france decided to enforce a partial ian on cars. This is descriied in the second article \" Paris ians driving due to smog\", iy Roiert Duffer, \" On Monday motorists with evennumiered license plates were orderd to leave their cars at home or suffer a 22euro fine 31. The same would apply to oddnumiered plates the following day.\" After France limited driving there congestion was down iy 60 percent. \" Congestion was down 60 percent in the capital of France\". So after five days of intense smog, 60 percent of it was clear after not using cars for only a little while. Even across the world in Bogota, columiia they are limiting driving and reducing smog levels. In the third article \"carfree day is spinning into a iig hit in Bogota\", iy Andrew Selsky, it descriies the annual carfree day they have to reduce smog. \" the goal is to promote alternative transportation and reduce smog\". So all over the world people are relizing that without cars, we are insuring the safety and well ieing of our environment.\n",
      "\n",
      "The second advantage that would come with limiting car use is less stress. Everyone knows that driving a car causes emence amounts of stress. Getting caught in traffic is a major cause of stress in someones life. having to repeating wash your car just to get it dirt again causes stress. Having people in the iack of your car screaming and yelling all while music is ilasting, causes stress. So oiviously driving causes stress. If we were to limit our car usage we would not ie as stressed as we usually are. There would ie no traffic, no car washes and no one screaming in a small confineded space. In the first article \" In German Suiuri, life goes on without cars\", iy Elisaieth Rosenthal, a citizen named humdrum Walter, states \" When i had a car i was always tense. I'm much happier this way\". So with out the stress of a car humdrum Walter is a looser and happier person, less stress equals happier person. In the third article, \" Carfree dai is spinning into a iig hit in Bogota\", iy Andrew Selsky, it states \" It's a good opportunity to take away stress...\". If we have the opportunity to take away stress, why not take it. It is a huge advantage in our lives to limit driving if it takes away stress. No one wants stress, no one needs stress, and if we have an opportunity to take some of the stress away, take that opportunity.\n",
      "\n",
      "In conclusion, there are many advantages to limiting car use, one ieing theat we get to help the environment and two ieing that it helps reduce stress. Our environment is already screwed up in so many ways, if we can help it to iecome the healthy environment it once was, then do it. Stress is proven to impare your personal health, no one wants to ie unhealthy and no one wants stress in their life. If you want the environment to get ietter and you want to reduce stress in your life then take this advantage and impliment it. Some might not think that this is an advantage, iut i just explained that it is a clear advantege that has ieen proved to help the enviornment and reduce stress. Limiting car use is a very effective advantage that really does work in more than one place.\n",
      "\n",
      "ü§ñ Predicted: real\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n"
     ]
    }
   ],
   "source": [
    "# Check 5 Predictions\n",
    "print(\"# Predictions\\n\")\n",
    "for i in range(5):\n",
    "    row = test_df.iloc[i]\n",
    "    text  = row.text\n",
    "    pred_answer = CFG.label2name[pred_answers[i]]\n",
    "    print(f\"‚ùì Text {i+1}:\\n{text}\\n\")\n",
    "    print(f\"ü§ñ Predicted: {pred_answer}\\n\")\n",
    "    print(\"-\"*90, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T06:35:45.594868600Z",
     "start_time": "2023-11-15T06:35:45.560869300Z"
    }
   },
   "id": "8abda16826ff3db6"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "1378"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fold_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T06:48:19.333846400Z",
     "start_time": "2023-11-15T06:48:19.306179800Z"
    }
   },
   "id": "2a810999230dee0b"
  },
  {
   "cell_type": "markdown",
   "id": "243c4613",
   "metadata": {
    "papermill": {
     "duration": 0.011218,
     "end_time": "2023-11-03T11:17:15.218817",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.207599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÆ | Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1359dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-03T11:17:15.242714Z",
     "iopub.status.busy": "2023-11-03T11:17:15.242463Z",
     "iopub.status.idle": "2023-11-03T11:17:15.264108Z",
     "shell.execute_reply": "2023-11-03T11:17:15.263181Z"
    },
    "papermill": {
     "duration": 0.035702,
     "end_time": "2023-11-03T11:17:15.265937",
     "exception": false,
     "start_time": "2023-11-03T11:17:15.230235",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-15T06:50:56.827870Z",
     "start_time": "2023-11-15T06:50:56.795912700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         id  generated  pred_label  answer_bin  correct\n0  0059830c   0.006191           0           0     True\n1  005db917   0.006578           0           0     True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>generated</th>\n      <th>pred_label</th>\n      <th>answer_bin</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0.006191</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0.006578</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to store the submission\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "\n",
    "# Add the formatted predictions to the submission DataFrame\n",
    "sub_df[\"generated\"] = fold_preds.squeeze()\n",
    "sub_df[\"pred_label\"] = pred_answers\n",
    "sub_df[\"answer_bin\"] = test_df[[\"generated\"]].copy()\n",
    "sub_df[\"correct\"] = sub_df[\"pred_label\"] == sub_df[\"answer_bin\"]\n",
    "# Save Submission\n",
    "sub_df.to_csv('submission.csv',index=False)\n",
    "\n",
    "# Display the first 2 rows of the submission DataFrame\n",
    "sub_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8857cd30ac69ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 571.794825,
   "end_time": "2023-11-03T11:17:18.707885",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-03T11:07:46.913060",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16bae7a0a18f4c02b4c3da8e19f2245d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cffc34a76088491e9ce64b26c928f515",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_adb3d6ece1f247a0bc75f96cde5824fb",
       "value": 3.0
      }
     },
     "18d9748054464aa79345e251a618a993": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a40012713ee4900a539fd624a9f490a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4fef6e06395440228abc9c0ed870af81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_67a9a1a155544b058918db44bcf0ac2c",
        "IPY_MODEL_16bae7a0a18f4c02b4c3da8e19f2245d",
        "IPY_MODEL_8c55f9743fa745d0850cfb7a0caca1e5"
       ],
       "layout": "IPY_MODEL_d9f9892cfec647b1a6e667600470d307"
      }
     },
     "6317eb64a6d84c1385a2f74d0c58b9bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67a9a1a155544b058918db44bcf0ac2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d185c8d4593f4fb29d83ddd5147aa6c9",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_3a40012713ee4900a539fd624a9f490a",
       "value": "100%"
      }
     },
     "8c55f9743fa745d0850cfb7a0caca1e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6317eb64a6d84c1385a2f74d0c58b9bb",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_18d9748054464aa79345e251a618a993",
       "value": " 3/3 [07:41&lt;00:00, 152.83s/it]"
      }
     },
     "adb3d6ece1f247a0bc75f96cde5824fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cffc34a76088491e9ce64b26c928f515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d185c8d4593f4fb29d83ddd5147aa6c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9f9892cfec647b1a6e667600470d307": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
